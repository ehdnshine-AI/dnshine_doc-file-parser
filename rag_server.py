from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import chromadb
from openai import OpenAI
import os
from typing import List, Optional
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="RAG API Server",
    description="ChromaDBì™€ OpenAIë¥¼ ì‚¬ìš©í•œ RAG ì‹œìŠ¤í…œ",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

# ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
chroma_client = chromadb.PersistentClient(path="./chroma_db")
collection = chroma_client.get_or_create_collection(name="md_documents")

# ìš”ì²­/ì‘ë‹µ ëª¨ë¸
class QueryRequest(BaseModel):
    question: str
    n_results: Optional[int] = 3
    model: Optional[str] = "gpt-4o-mini"

class SearchResult(BaseModel):
    content: str
    source: str
    filename: str
    chunk_index: int

class QueryResponse(BaseModel):
    answer: str
    sources: List[SearchResult]
    model_used: str

class HealthResponse(BaseModel):
    status: str
    documents_count: int

def get_openai_embedding(text: str):
    """OpenAI ì„ë² ë”© ìƒì„±"""
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    return response.data[0].embedding

def search_similar_documents(query: str, n_results: int = 3):
    """ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰"""
    query_embedding = get_openai_embedding(query)
    
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=n_results
    )
    
    return results

def generate_answer(question: str, context_docs: list, model: str = "gpt-4o-mini"):
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±"""
    
    # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context = "\n\n".join([
        f"[ë¬¸ì„œ {i+1}]\n{doc}" 
        for i, doc in enumerate(context_docs)
    ])
    
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , ì œê³µëœ ë¬¸ì„œì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ í•´ì£¼ì„¸ìš”.
ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì´ë¼ë©´ "ì œê³µëœ ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•´ì£¼ì„¸ìš”.

ì°¸ê³  ë¬¸ì„œ:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:"""
    
    # OpenAI API í˜¸ì¶œ
    response = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µì„ ìˆ˜í–‰í•˜ëŠ” ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3,
        max_tokens=1000
    )
    
    return response.choices[0].message.content

@app.get("/", response_model=dict)
async def root():
    """API ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "RAG API ì„œë²„ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤",
        "version": "1.0.0",
        "endpoints": {
            "health": "GET /health - ì„œë²„ ìƒíƒœ í™•ì¸",
            "query": "POST /query - RAG ì§ˆì˜ì‘ë‹µ",
            "search": "POST /search - ë¬¸ì„œ ê²€ìƒ‰ë§Œ",
            "docs": "GET /docs - API ë¬¸ì„œ (Swagger UI)"
        }
    }

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    try:
        doc_count = collection.count()
        return HealthResponse(
            status="healthy",
            documents_count=doc_count
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì„œë²„ ì˜¤ë¥˜: {str(e)}")

@app.post("/query", response_model=QueryResponse)
async def query_rag(request: QueryRequest):
    """RAG ì§ˆì˜ì‘ë‹µ"""
    try:
        # 1. ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
        search_results = search_similar_documents(
            request.question, 
            request.n_results
        )
        
        if not search_results['documents'][0]:
            raise HTTPException(
                status_code=404, 
                detail="ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            )
        
        # 2. LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±
        answer = generate_answer(
            request.question,
            search_results['documents'][0],
            request.model
        )
        
        # 3. ì‘ë‹µ êµ¬ì„±
        sources = [
            SearchResult(
                content=doc[:200] + "..." if len(doc) > 200 else doc,
                source=meta.get('source', 'unknown'),
                filename=meta.get('filename', 'unknown'),
                chunk_index=meta.get('chunk_index', 0)
            )
            for doc, meta in zip(
                search_results['documents'][0],
                search_results['metadatas'][0]
            )
        ]
        
        return QueryResponse(
            answer=answer,
            sources=sources,
            model_used=request.model
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")

@app.post("/search")
async def search_documents(request: QueryRequest):
    """ë¬¸ì„œ ê²€ìƒ‰ë§Œ ìˆ˜í–‰ (LLM ë‹µë³€ ì—†ì´)"""
    try:
        search_results = search_similar_documents(
            request.question,
            request.n_results
        )
        
        if not search_results['documents'][0]:
            return {"results": [], "message": "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
        
        results = [
            {
                "content": doc,
                "source": meta.get('source', 'unknown'),
                "filename": meta.get('filename', 'unknown'),
                "chunk_index": meta.get('chunk_index', 0),
                "similarity_score": 1 - dist  # distanceë¥¼ similarityë¡œ ë³€í™˜
            }
            for doc, meta, dist in zip(
                search_results['documents'][0],
                search_results['metadatas'][0],
                search_results['distances'][0]
            )
        ]
        
        return {
            "results": results,
            "total": len(results)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ RAG API ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("ğŸ“– API ë¬¸ì„œ: http://localhost:8000/docs")
    uvicorn.run(app, host="0.0.0.0", port=8000)